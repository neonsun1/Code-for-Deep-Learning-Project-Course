{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06c75c12-da23-451c-b871-e6708748394d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-10 22:57:31.092088: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1736521051.224286    4392 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1736521051.260204    4392 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-01-10 22:57:31.594156: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f584c539b0a4716a9728ba587a03b02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "StableDiffusionInpaintPipeline {\n",
       "  \"_class_name\": \"StableDiffusionInpaintPipeline\",\n",
       "  \"_diffusers_version\": \"0.31.0\",\n",
       "  \"_name_or_path\": \"./stable-diffusion-2-inpainting\",\n",
       "  \"feature_extractor\": [\n",
       "    \"transformers\",\n",
       "    \"CLIPImageProcessor\"\n",
       "  ],\n",
       "  \"image_encoder\": [\n",
       "    null,\n",
       "    null\n",
       "  ],\n",
       "  \"requires_safety_checker\": false,\n",
       "  \"safety_checker\": [\n",
       "    null,\n",
       "    null\n",
       "  ],\n",
       "  \"scheduler\": [\n",
       "    \"diffusers\",\n",
       "    \"PNDMScheduler\"\n",
       "  ],\n",
       "  \"text_encoder\": [\n",
       "    \"transformers\",\n",
       "    \"CLIPTextModel\"\n",
       "  ],\n",
       "  \"tokenizer\": [\n",
       "    \"transformers\",\n",
       "    \"CLIPTokenizer\"\n",
       "  ],\n",
       "  \"unet\": [\n",
       "    \"diffusers\",\n",
       "    \"UNet2DConditionModel\"\n",
       "  ],\n",
       "  \"vae\": [\n",
       "    \"diffusers\",\n",
       "    \"AutoencoderKL\"\n",
       "  ]\n",
       "}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from diffusers import StableDiffusionInpaintPipeline\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch import Generator\n",
    "import gc\n",
    "# 加载预训练模型\n",
    "pipe = StableDiffusionInpaintPipeline.from_pretrained(\n",
    "    \"./stable-diffusion-2-inpainting\",\n",
    "    torch_dtype=torch.float16\n",
    ")\n",
    "pipe.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f480c77-c65d-4509-a007-45190ba2d6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InpaintingDataset(Dataset):\n",
    "    def __init__(self, original_image_dir, mask_dir, transform_img=None, transform_mask=None):\n",
    "        self.original_image_dir = original_image_dir\n",
    "        self.mask_dir = mask_dir\n",
    "        self.transform_img = transform_img\n",
    "        self.transform_mask = transform_mask\n",
    "\n",
    "        # 获取原始图像和掩码图像的路径\n",
    "        self.image_paths = []\n",
    "        for subdir in os.listdir(original_image_dir):\n",
    "            image_subdir = os.path.join(original_image_dir, subdir)\n",
    "            mask_subdir = os.path.join(mask_dir, subdir)          \n",
    "            self.image_paths.append((image_subdir, mask_subdir))\n",
    "        print(f\"Loaded {len(self.image_paths)} image-mask pairs\")\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, mask_path = self.image_paths[idx]\n",
    "\n",
    "        # 读取原始图像和掩码图像\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        mask = Image.open(mask_path).convert(\"1\")  # mask是单通道图像\n",
    "\n",
    "        # 应用数据增强和预处理\n",
    "        if self.transform_img:\n",
    "            img = self.transform_img(img)\n",
    "        if self.transform_mask:\n",
    "            mask = self.transform_mask(mask)\n",
    "        \n",
    "        return img, mask\n",
    "\n",
    "transform_img = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711]),\n",
    "])\n",
    "\n",
    "# 为掩码图像定义数据增强（不进行归一化）\n",
    "transform_mask = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "182ac9c0-7154-4419-a849-ffc907e3243a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4392/1612876969.py:103: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  pipe.unet.load_state_dict(torch.load(model_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 200 image-mask pairs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing face:   0%|                                      | 0/13 [00:00<?, ?it/s]/home/neonsun/miniconda3/envs/sd/lib/python3.10/site-packages/diffusers/image_processor.py:704: FutureWarning: Passing `image` as torch tensor with value range in [-1,1] is deprecated. The expected value range for image tensor is [0,1] when passing as pytorch tensor or numpy Array. You passed `image` with value range [-1.7922625541687012,2.1458969116210938]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d06c94cdc1345b68086791f691c6431",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4392/1612876969.py:67: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n",
      "  return image.resize(target_size, Image.ANTIALIAS)\n",
      "Testing face:   8%|██▏                          | 1/13 [01:42<20:25, 102.16s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd4d1fca39124e6e83aef8fc8a8ef110",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing face:  15%|████▍                        | 2/13 [03:24<18:45, 102.33s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94da57e397c74fa085736d6bacae1544",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing face:  23%|██████▋                      | 3/13 [05:06<17:02, 102.22s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f628006643a84fa78728c3a630652c48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing face:  31%|████████▉                    | 4/13 [06:48<15:19, 102.16s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c1ce3e7c00249d4821235184188f3df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing face:  38%|███████████▏                 | 5/13 [08:31<13:37, 102.19s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3cde8a37e894b1bbed490ac7f18cecc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing face:  46%|█████████████▍               | 6/13 [10:14<11:58, 102.68s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "025d1db684ec4fd49b9e28741f3d20ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing face:  54%|███████████████▌             | 7/13 [12:03<10:28, 104.69s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "052343bcb9614f3d83b0aa741cf24596",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing face:  62%|█████████████████▊           | 8/13 [13:50<08:47, 105.46s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d10d1063bd14052bf2c72a043785e05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing face:  69%|████████████████████         | 9/13 [15:34<06:59, 104.97s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "656b8cf77d6d4917ba0c973d9d6d512b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing face:  77%|█████████████████████▌      | 10/13 [17:16<05:12, 104.15s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1be25be1762489bb66f47beb389efbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing face:  85%|███████████████████████▋    | 11/13 [19:00<03:28, 104.08s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eeb4823a56444361a00e1fa969ddf099",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing face:  92%|█████████████████████████▊  | 12/13 [20:43<01:43, 103.54s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "398449e565f7441e90e5efed1ced6faa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing face: 100%|█████████████████████████████| 13/13 [21:34<00:00, 99.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average metrics for face:\n",
      "{'PSNR': 7.264619312404474, 'SSIM': 0.24801716435700655, 'VIF': 0.020357388166735615}\n",
      "Loaded 200 image-mask pairs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing scenario:   0%|                                  | 0/13 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a2fa11678a64ab6ae705c9bbab9e9e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing scenario:   8%|█▉                       | 1/13 [01:42<20:27, 102.32s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de53c949dac145d5a4860b081452ad47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing scenario:  15%|███▊                     | 2/13 [03:24<18:45, 102.31s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc567dce54124f75a7c98ef46f43e0e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing scenario:  23%|█████▊                   | 3/13 [05:06<17:02, 102.30s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2811bf37618240a1af5db7c3ec86f521",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing scenario:  31%|███████▋                 | 4/13 [06:49<15:20, 102.30s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30d36511ac684acaa6939c2cde79ac57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing scenario:  38%|█████████▌               | 5/13 [08:31<13:38, 102.29s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2aeb4aca5e744219acf92ab39caa315f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing scenario:  46%|███████████▌             | 6/13 [10:13<11:55, 102.25s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8d10ade0b71487991883e170029405e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing scenario:  54%|█████████████▍           | 7/13 [11:55<10:13, 102.28s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a93a0c2b1b54a38a4f239e23b70c485",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing scenario:  62%|███████████████▍         | 8/13 [13:40<08:34, 102.90s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71572df72a124ce68f0bd8a225b38b67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing scenario:  69%|█████████████████▎       | 9/13 [15:22<06:50, 102.73s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c060b839d165497099662b5a7e21fb21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing scenario:  77%|██████████████████▍     | 10/13 [17:04<05:07, 102.55s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd5e35b9a03c4d55b88fc9df1519af35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing scenario:  85%|████████████████████▎   | 11/13 [18:46<03:24, 102.43s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ccf5405872c4d48b4d18f42ce4edbec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing scenario:  92%|██████████████████████▏ | 12/13 [20:28<01:42, 102.33s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4040f8436a4543f4b22986170f0b8325",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing scenario: 100%|█████████████████████████| 13/13 [21:19<00:00, 98.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average metrics for scenario:\n",
      "{'PSNR': 7.231791672698777, 'SSIM': 0.17244896695949138, 'VIF': 0.026071536946030118}\n",
      "Loaded 200 image-mask pairs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing street_scene_pairs:   0%|                        | 0/13 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14288c6283ab40bbbaa513e5952d7a9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing street_scene_pairs:   8%|█▏             | 1/13 [01:42<20:29, 102.46s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf4380f205bd43d49c0196f3906c4c06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing street_scene_pairs:  15%|██▎            | 2/13 [03:24<18:45, 102.35s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "511a7d6b4b974443a9468e658237566a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing street_scene_pairs:  23%|███▍           | 3/13 [05:06<17:02, 102.30s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59d241dd0c5d4656a80d86ef23575544",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing street_scene_pairs:  31%|████▌          | 4/13 [06:49<15:20, 102.25s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebe7c2623c3d4febb194015dc24e0888",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing street_scene_pairs:  38%|█████▊         | 5/13 [08:31<13:38, 102.27s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd06499a123e482dba409f2a3ccd5be8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing street_scene_pairs:  46%|██████▉        | 6/13 [10:13<11:55, 102.28s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7804c4f2343b447781e869248f6e48ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing street_scene_pairs:  54%|████████       | 7/13 [11:55<10:13, 102.26s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c2b7d30e4ea4336a6e150cf40a51ef6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing street_scene_pairs:  62%|█████████▏     | 8/13 [13:38<08:31, 102.26s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "542c6010720c4861a25cd88631c575ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing street_scene_pairs:  69%|██████████▍    | 9/13 [15:20<06:49, 102.30s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ace80e77f4af4b9793aafc1e78ce01cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing street_scene_pairs:  77%|██████████▊   | 10/13 [17:02<05:06, 102.27s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c729aa208d742728ece91b43f8b4030",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing street_scene_pairs:  85%|███████████▊  | 11/13 [18:45<03:24, 102.27s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "affc71a8f78f43e0b6c0110490aecbd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing street_scene_pairs:  92%|████████████▉ | 12/13 [20:27<01:42, 102.24s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fc26b27886547538008114315b1eea0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing street_scene_pairs: 100%|███████████████| 13/13 [21:18<00:00, 98.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average metrics for street_scene_pairs:\n",
      "{'PSNR': 7.27517793389928, 'SSIM': 0.1873990525305271, 'VIF': 0.024900372341543617}\n",
      "Loaded 200 image-mask pairs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing texture:   0%|                                   | 0/13 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c8dbc518a0d4d72b3b11c0ced7a629c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing texture:   8%|██                        | 1/13 [01:42<20:24, 102.05s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9175f883f4cd4ce29ef0f77834a68e26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing texture:  15%|████                      | 2/13 [03:24<18:42, 102.02s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24e9bf205f2449c3b0e35f7c9d56a1c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing texture:  23%|██████                    | 3/13 [05:06<17:00, 102.04s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17b982cef45144829096c5d3774a4d48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing texture:  31%|████████                  | 4/13 [06:48<15:18, 102.03s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a36ef3c71f9f4fc497222ad929116fc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing texture:  38%|██████████                | 5/13 [08:30<13:36, 102.01s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4024eac408d94f55a3c6ec385fdcb07b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing texture:  46%|████████████              | 6/13 [10:12<11:53, 101.99s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75e62f0db9bf4710a71c68eb3e024d99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing texture:  54%|██████████████            | 7/13 [11:54<10:12, 102.02s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8743bfe67b28415cba9bf9581910ce44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing texture:  62%|████████████████          | 8/13 [13:36<08:30, 102.02s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b90616e682bf49c58dbf85dd3552474f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing texture:  69%|██████████████████        | 9/13 [15:18<06:48, 102.02s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ebfedf5e4d949388fff7f640f2fc7f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing texture:  77%|███████████████████▏     | 10/13 [17:00<05:05, 102.00s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bdc2ae5a7fc46f3a8343c66b4e2170c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing texture:  85%|█████████████████████▏   | 11/13 [18:42<03:23, 101.96s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c44b379459a41b3bcc9a05e1c1791ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing texture:  92%|███████████████████████  | 12/13 [20:23<01:41, 101.93s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c0226cdb32c45f597d5c8d027e906bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing texture: 100%|██████████████████████████| 13/13 [21:14<00:00, 98.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average metrics for texture:\n",
      "{'PSNR': 8.125930449558334, 'SSIM': 0.09555807177952375, 'VIF': 0.0769037612807758}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr, structural_similarity as ssim\n",
    "from sewar.full_ref import vifp  # 第三方库 sewar 提供 VIF 和 FSIM 的实现\n",
    "import numpy as np\n",
    "import json\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "\n",
    "def calculate_metrics(original, generated):\n",
    "    \"\"\"\n",
    "    计算图像质量评估指标\n",
    "    :param original: 原始图像 (H, W, C) 格式\n",
    "    :param generated: 生成图像 (H, W, C) 格式\n",
    "    :return: 指标字典\n",
    "    \"\"\"\n",
    "    \n",
    "   \n",
    "    \n",
    "    # # 确保图像被标准化到 [0, 1]\n",
    "    original = np.array(original).astype(np.float32) / 255.0\n",
    "    generated = np.array(generated).astype(np.float32) / 255.0    \n",
    "\n",
    "\n",
    "\n",
    "    # 如果图像只有单通道，增加通道维度\n",
    "    if original.ndim == 2:\n",
    "        original = np.expand_dims(original, axis=-1)\n",
    "    if generated.ndim == 2:\n",
    "        generated = np.expand_dims(generated, axis=-1)\n",
    "    \n",
    "    # PSNR\n",
    "    psnr_value = psnr(original, generated, data_range=1)\n",
    "\n",
    "     # SSIM \n",
    "    ssim_value, _ = ssim(\n",
    "    original, \n",
    "    generated, \n",
    "    channel_axis=-1,  # 指定通道轴为最后一维\n",
    "    data_range=1.0, \n",
    "    full=True, \n",
    "    win_size=7\n",
    ")\n",
    "\n",
    "    \n",
    "    # VIF\n",
    "    vif_value = vifp(original, generated)\n",
    "\n",
    "    return {\n",
    "        \"PSNR\": psnr_value,\n",
    "        \"SSIM\": ssim_value,\n",
    "        \"VIF\": vif_value,\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "generator = Generator()\n",
    "generator.manual_seed(42)\n",
    "\n",
    "def adjust_image_size(image, target_size):\n",
    "    \"\"\"\n",
    "    调整图像大小以匹配目标尺寸。\n",
    "    :param image: 输入的PIL图像对象\n",
    "    :param target_size: 目标尺寸 (宽度, 高度)\n",
    "    :return: 调整大小后的PIL图像对象\n",
    "    \"\"\"\n",
    "    return image.resize(target_size, Image.ANTIALIAS)\n",
    "    \n",
    "def tensor_to_image(tensor):\n",
    "    \"\"\"\n",
    "    将PyTorch张量转换为PIL图像\n",
    "    :param tensor: 输入的PyTorch张量 (C, H, W)\n",
    "    :return: PIL图像对象\n",
    "    \"\"\"\n",
    "    tensor = tensor.cpu().clone()  # 克隆张量以避免修改原张量\n",
    "    tensor = tensor.squeeze(0)  # 移除batch维度\n",
    "    # unnormalize = transforms.Normalize(mean=[-0.485/0.229, -0.456/0.224, -0.406/0.225], std=[1/0.229, 1/0.224, 1/0.225])\n",
    "    # tensor = unnormalize(tensor)  # 反归一化（如果之前进行了归一化）\n",
    "    # tensor = torch.clamp(tensor, 0, 1)  # 确保像素值在[0, 1]之间\n",
    "    image = transforms.ToPILImage()(tensor)\n",
    "    return image\n",
    "\n",
    "\n",
    "def save_image(image, output_dir, filename):\n",
    "    \"\"\"\n",
    "    保存图像到指定目录\n",
    "    :param image: PIL图像对象\n",
    "    :param output_dir: 输出目录路径\n",
    "    :param filename: 文件名\n",
    "    \"\"\"\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    image.save(os.path.join(output_dir, filename))\n",
    "\n",
    "               \n",
    "\n",
    "def test_model(image_type, model_path, output_dir=\"./output_images_sd\"):\n",
    "    \"\"\"\n",
    "    测试针对特定图像类型的模型并计算图像质量评估指标平均值\n",
    "    \"\"\"\n",
    "    output_dir += \"/\" + image_type\n",
    "    # 加载模型权重\n",
    "    pipe.unet.load_state_dict(torch.load(model_path))\n",
    "    pipe.unet.eval()  # 设置为评估模式\n",
    "\n",
    "    original_image_dir = f\"./dataset_test/original_image/{image_type}\"\n",
    "    mask_dir = f\"./dataset_test/mask/{image_type}\"\n",
    "\n",
    "    test_dataset = InpaintingDataset(\n",
    "        original_image_dir=original_image_dir,\n",
    "        mask_dir=mask_dir,\n",
    "        transform_img=transform_img,\n",
    "        transform_mask=transform_mask\n",
    "    )\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "    # 初始化累计值\n",
    "    metrics_sum = {\"PSNR\": 0.0, \"SSIM\": 0.0, \"VIF\": 0.0}\n",
    "    total_images = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(tqdm(test_dataloader, desc=f\"Testing {image_type}\")):\n",
    "            images, masks = batch\n",
    "            images, masks = images.cuda(), masks.cuda()\n",
    "\n",
    "            prompt = [\" \"] * images.size(0)\n",
    "\n",
    "            inputs = pipe.tokenizer(\n",
    "                prompt,\n",
    "                padding=\"max_length\",\n",
    "                truncation=True,\n",
    "                return_tensors=\"pt\",\n",
    "                max_length=pipe.tokenizer.model_max_length\n",
    "            )\n",
    "\n",
    "            for k, v in inputs.items():\n",
    "                inputs[k] = v.cuda()\n",
    "\n",
    "            prompt_embeds = pipe.text_encoder(\n",
    "                inputs.input_ids, attention_mask=inputs.attention_mask\n",
    "            ).last_hidden_state\n",
    "\n",
    "            outputs = pipe(\n",
    "                image=images,\n",
    "                mask_image=masks,\n",
    "                prompt_embeds=prompt_embeds,\n",
    "                generator=generator,\n",
    "                num_inference_steps=50,\n",
    "                guidance_scale=7.5\n",
    "            ).images\n",
    "\n",
    "            if isinstance(outputs, (list, tuple)):\n",
    "                outputs = torch.stack([transforms.ToTensor()(img) for img in outputs]).cuda()\n",
    "\n",
    "            for i in range(outputs.size(0)):\n",
    "                \n",
    "                output_image = tensor_to_image(outputs[i])\n",
    "                filename = f\"generated_image_{batch_idx * len(images) + i + 1}.png\"\n",
    "                save_image(output_image, output_dir, filename)\n",
    "                original_image = tensor_to_image(images[i])\n",
    "\n",
    "                \n",
    "                # 如果需要，调整输出图像大小以匹配原始图像\n",
    "                if output_image.size != original_image.size:\n",
    "                    original_image = adjust_image_size(original_image, output_image.size)\n",
    "                    \n",
    "\n",
    "                # 计算指标\n",
    "                metrics = calculate_metrics(original_image, output_image)\n",
    "                for key in metrics_sum:\n",
    "                    metrics_sum[key] += metrics[key]\n",
    "                total_images += 1\n",
    "                \n",
    "\n",
    "            del images, masks, outputs, prompt_embeds\n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "    \n",
    "    # 计算平均值\n",
    "    metrics_avg = {key: metrics_sum[key] / total_images for key in metrics_sum}\n",
    "\n",
    "    # 保存平均值\n",
    "    metrics_file = os.path.join(output_dir, f\"{image_type}_average_metrics_sd.json\")\n",
    "    with open(metrics_file, \"w\") as f:\n",
    "        json.dump(metrics_avg, f, indent=4)\n",
    "\n",
    "    # 打印结果\n",
    "    print(f\"Average metrics for {image_type}:\")\n",
    "    print(metrics_avg)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 示例：测试 'face' 类型的模型\n",
    "    image_types = [\"face\", \"scenario\", \"street_scene_pairs\", \"texture\"]\n",
    "    for image_type in image_types:\n",
    "        model_path = f'unet_model_{image_type}.pth'\n",
    "        test_model(image_type=image_type, model_path=model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b650e5-a55f-4958-90d6-bbc8292160fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sd",
   "language": "python",
   "name": "sd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
